{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ce047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  code from https://github.com/dominance-analysis/dominance-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f04a72-3e57-485f-a647-40f923e3b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainstat import datasets\n",
    "from neuromaps.nulls.spins import gen_spinsamples\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import netneurotools\n",
    "from netneurotools import datasets, utils\n",
    "from scipy.stats import zscore, pearsonr, ttest_ind\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "def get_reg_r_sq(X, y):\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X, y)\n",
    "    yhat = lin_reg.predict(X)\n",
    "    SS_Residual = sum((y - yhat) ** 2)\n",
    "    SS_Total = sum((y - np.mean(y)) ** 2)\n",
    "    r_squared = 1 - (float(SS_Residual)) / SS_Total\n",
    "    adjusted_r_squared = 1 - (1 - r_squared) * \\\n",
    "        (len(y) - 1) / (len(y) - X.shape[1] - 1)\n",
    "    return adjusted_r_squared\n",
    "\n",
    "\n",
    "def cv_slr_distance_dependent(X, y, coords, train_pct=.75, metric='rsq'):\n",
    "    '''\n",
    "    cross validates linear regression model using distance-dependent method.\n",
    "    X = n x p matrix of input variables\n",
    "    y = n x 1 matrix of output variable\n",
    "    coords = n x 3 coordinates of each observation\n",
    "    train_pct (between 0 and 1), percent of observations in training set\n",
    "    metric = {'rsq', 'corr'}\n",
    "    '''\n",
    "\n",
    "    P = squareform(pdist(coords, metric=\"euclidean\"))\n",
    "    train_metric = []\n",
    "    test_metric = []\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        distances = P[i, :]  # for every node\n",
    "        idx = np.argsort(distances)\n",
    "\n",
    "        train_idx = idx[:int(np.floor(train_pct * len(coords)))]\n",
    "        test_idx = idx[int(np.floor(train_pct * len(coords))):]\n",
    "\n",
    "        mdl = LinearRegression()\n",
    "        mdl.fit(X[train_idx, :], y[train_idx])\n",
    "        if metric == 'rsq':\n",
    "            # get r^2 of train set\n",
    "            train_metric.append(get_reg_r_sq(X[train_idx, :], y[train_idx]))\n",
    "\n",
    "        elif metric == 'corr':\n",
    "            rho, _ = pearsonr(mdl.predict(X[train_idx, :]), y[train_idx])\n",
    "            train_metric.append(rho)\n",
    "\n",
    "        yhat = mdl.predict(X[test_idx, :])\n",
    "        if metric == 'rsq':\n",
    "            # get r^2 of test set\n",
    "            SS_Residual = sum((y[test_idx] - yhat) ** 2)\n",
    "            SS_Total = sum((y[test_idx] - np.mean(y[test_idx])) ** 2)\n",
    "            r_squared = 1 - (float(SS_Residual)) / SS_Total\n",
    "            adjusted_r_squared = 1-(1-r_squared)*((len(y[test_idx]) - 1) /\n",
    "                                                  (len(y[test_idx]) -\n",
    "                                                   X.shape[1]-1))\n",
    "            test_metric.append(adjusted_r_squared)\n",
    "\n",
    "        elif metric == 'corr':\n",
    "            rho, _ = pearsonr(yhat, y[test_idx])\n",
    "            test_metric.append(rho)\n",
    "\n",
    "    return train_metric, test_metric\n",
    "\n",
    "\n",
    "def get_perm_p(emp, null):\n",
    "    return (1 + sum(abs(null - np.mean(null))\n",
    "                    > abs(emp - np.mean(null)))) / (len(null) + 1)\n",
    "\n",
    "\n",
    "def get_reg_r_pval(X, y, spins, nspins):\n",
    "    emp = get_reg_r_sq(X, y)\n",
    "    null = np.zeros((nspins, ))\n",
    "    for s in range(nspins):\n",
    "        null[s] = get_reg_r_sq(X[spins[:, s], :], y)\n",
    "    return (1 + sum(null > emp))/(nspins + 1)\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from scipy import optimize, spatial, special, stats as sstats\n",
    "from sklearn.utils.validation import check_random_state\n",
    "from sklearn.linear_model import LinearRegression\n",
    "def get_dominance_stats(X, y, use_adjusted_r_sq=True, verbose=False):\n",
    "    \"\"\"\n",
    "    Returns the dominance analysis statistics for multilinear regression.\n",
    "\n",
    "    This is a rewritten & simplified version of [DA1]_. It is briefly\n",
    "    tested against the original package, but still in early stages.\n",
    "    Please feel free to report any bugs.\n",
    "\n",
    "    Warning: Still work-in-progress. Parameters might change!\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : (N, M) array_like\n",
    "        Input data\n",
    "    y : (N,) array_like\n",
    "        Target values\n",
    "    use_adjusted_r_sq : bool, optional\n",
    "        Whether to use adjusted r squares. Default: True\n",
    "    verbose : bool, optional\n",
    "        Whether to print debug messages. Default: False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model_metrics : dict\n",
    "        The dominance metrics, currently containing `individual_dominance`,\n",
    "        `partial_dominance`, `total_dominance`, and `full_r_sq`.\n",
    "    model_r_sq : dict\n",
    "        Contains all model r squares\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Example usage\n",
    "\n",
    "    .. code:: python\n",
    "\n",
    "        from netneurotools.stats import get_dominance_stats\n",
    "        from sklearn.datasets import load_boston\n",
    "        X, y = load_boston(return_X_y=True)\n",
    "        model_metrics, model_r_sq = get_dominance_stats(X, y)\n",
    "\n",
    "    To compare with [DA1]_, use `use_adjusted_r_sq=False`\n",
    "\n",
    "    .. code:: python\n",
    "\n",
    "        from dominance_analysis import Dominance_Datasets\n",
    "        from dominance_analysis import Dominance\n",
    "        boston_dataset=Dominance_Datasets.get_boston()\n",
    "        dominance_regression=Dominance(data=boston_dataset,\n",
    "                                       target='House_Price',objective=1)\n",
    "        incr_variable_rsquare=dominance_regression.incremental_rsquare()\n",
    "        dominance_regression.dominance_stats()\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [DA1] https://github.com/dominance-analysis/dominance-analysis\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # this helps to remove one element from a tuple\n",
    "    def remove_ret(tpl, elem):\n",
    "        lst = list(tpl)\n",
    "        lst.remove(elem)\n",
    "        return tuple(lst)\n",
    "\n",
    "    # sklearn linear regression wrapper\n",
    "    def get_reg_r_sq(X, y):\n",
    "        lin_reg = LinearRegression()\n",
    "        lin_reg.fit(X, y)\n",
    "        yhat = lin_reg.predict(X)\n",
    "        SS_Residual = sum((y - yhat) ** 2)\n",
    "        SS_Total = sum((y - np.mean(y)) ** 2)\n",
    "        r_squared = 1 - (float(SS_Residual)) / SS_Total\n",
    "        adjusted_r_squared = 1 - (1 - r_squared) * \\\n",
    "            (len(y) - 1) / (len(y) - X.shape[1] - 1)\n",
    "        if use_adjusted_r_sq:\n",
    "            return adjusted_r_squared\n",
    "        else:\n",
    "            return r_squared\n",
    "\n",
    "    # generate all predictor combinations in list (num of predictors) of lists\n",
    "    n_predictor = X.shape[-1]\n",
    "    # n_comb_len_group = n_predictor - 1\n",
    "    predictor_combs = [list(combinations(range(n_predictor), i))\n",
    "                       for i in range(1, n_predictor + 1)]\n",
    "    if verbose:\n",
    "        print(f\"[Dominance analysis] Generated \\\n",
    "              {len([v for i in predictor_combs for v in i])} combinations\")\n",
    "\n",
    "    # get all r_sq's\n",
    "    model_r_sq = dict()\n",
    "    for len_group in tqdm(predictor_combs, desc='num-of-predictor loop',\n",
    "                          disable=not verbose):\n",
    "        for idx_tuple in tqdm(len_group, desc='insider loop',\n",
    "                              disable=not verbose):\n",
    "            r_sq = get_reg_r_sq(X[:, idx_tuple], y)\n",
    "            model_r_sq[idx_tuple] = r_sq\n",
    "    if verbose:\n",
    "        print(f\"[Dominance analysis] Acquired {len(model_r_sq)} r^2's\")\n",
    "\n",
    "    # getting all model metrics\n",
    "    model_metrics = dict([])\n",
    "\n",
    "    # individual dominance\n",
    "    individual_dominance = []\n",
    "    for i_pred in range(n_predictor):\n",
    "        individual_dominance.append(model_r_sq[(i_pred,)])\n",
    "    individual_dominance = np.array(individual_dominance).reshape(1, -1)\n",
    "    model_metrics[\"individual_dominance\"] = individual_dominance\n",
    "\n",
    "    # partial dominance\n",
    "    partial_dominance = [[] for _ in range(n_predictor - 1)]\n",
    "    for i_len in range(n_predictor - 1):\n",
    "        i_len_combs = list(combinations(range(n_predictor), i_len + 2))\n",
    "        for j_node in range(n_predictor):\n",
    "            j_node_sel = [v for v in i_len_combs if j_node in v]\n",
    "            reduced_list = [remove_ret(comb, j_node) for comb in j_node_sel]\n",
    "            diff_values = [\n",
    "                model_r_sq[j_node_sel[i]] - model_r_sq[reduced_list[i]]\n",
    "                for i in range(len(reduced_list))]\n",
    "            partial_dominance[i_len].append(np.mean(diff_values))\n",
    "\n",
    "    # save partial dominance\n",
    "    partial_dominance = np.array(partial_dominance)\n",
    "    model_metrics[\"partial_dominance\"] = partial_dominance\n",
    "    # get total dominance\n",
    "    total_dominance = np.mean(\n",
    "        np.r_[individual_dominance, partial_dominance], axis=0)\n",
    "    # test and save total dominance\n",
    "    assert np.allclose(total_dominance.sum(),\n",
    "                       model_r_sq[tuple(range(n_predictor))]), \\\n",
    "           \"Sum of total dominance is not equal to full r square!\"\n",
    "    model_metrics[\"total_dominance\"] = total_dominance\n",
    "    # save full r^2\n",
    "    model_metrics[\"full_r_sq\"] = model_r_sq[tuple(range(n_predictor))]\n",
    "\n",
    "    return model_metrics, model_r_sq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "853c6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "set-up\n",
    "\"\"\"\n",
    "\n",
    "path = 'your pathway/MIND/outcome/'\n",
    "\n",
    "# set up parcellation\n",
    "# coords_DK308_hemi\n",
    "hemiid = np.genfromtxt(path+'coords_DK308_hemi.txt')\n",
    "coords =  np.genfromtxt(path+'coords_DK308.txt')\n",
    "nnodes = 308\n",
    "nspins = 10000\n",
    "spins = gen_spinsamples(coords, hemiid, n_rotate=nspins, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "451281d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the receptor data (from neuromaps: https://netneurolab.github.io/neuromaps/usage.html)\n",
    "receptor_data = np.genfromtxt(path+'neuromaps_receptors_scaled_DK308.csv', delimiter=',')\n",
    "receptor_names = np.loadtxt(path+'nuromaps_receptor_names.txt', dtype='str')\n",
    "MIND_Dementia = np.genfromtxt(path+'final_Tmap_NC_Wu_NIFD_all_DK308.csv', delimiter=',')\n",
    "#MIND_Dementia = MIND_Dementia[:, 1:]\n",
    "disorders =  [\"FTD\", \"FTD-rep\", \"bvFTD\", \"bvFTD-rep\", \"svPPA\", \"svPPA-rep\", \"nfvPPA\", \"NC\", \"NC-rep\"];\n",
    "\n",
    "# colourmaps\n",
    "cmap = np.genfromtxt(path+'colourmap.csv', delimiter=',')\n",
    "cmap_div = ListedColormap(cmap)\n",
    "cmap_seq = ListedColormap(cmap[128:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9cd3551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the psychiatry data (from ENIGMA)\n",
    "receptor_data = np.genfromtxt(path+'psychiatry_6_scaled_DK68.csv', delimiter=',')\n",
    "receptor_names = np.loadtxt(path+'psychiatry_6_scaled_name.txt', dtype='str')\n",
    "MIND_Dementia = np.genfromtxt(path+'final_Tmap_NC_Wu_NIFD_all_DK68.csv', delimiter=',')\n",
    "#MIND_Dementia = MIND_Dementia[:, 1:]\n",
    "disorders =  [\"FTD\", \"FTD-rep\", \"bvFTD\", \"bvFTD-rep\", \"svPPA\", \"svPPA-rep\", \"nfvPPA\"];\n",
    "\n",
    "# colourmaps\n",
    "cmap = np.genfromtxt(path+'colourmap.csv', delimiter=',')\n",
    "cmap_div = ListedColormap(cmap)\n",
    "cmap_seq = ListedColormap(cmap[128:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9682b453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 6)\n",
      "['ADHD' 'ASD' 'BIPO' 'MDD' 'OCD' 'SZ']\n",
      "(68, 9)\n",
      "['FTD', 'FTD-rep', 'bvFTD', 'bvFTD-rep', 'SD', 'SD-rep', 'PNFA']\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(receptor_data.shape)\n",
    "print(receptor_names)\n",
    "print(MIND_Dementia.shape)\n",
    "print(disorders)\n",
    "#print(receptor_data)\n",
    "print(len(disorders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "873bd25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dominance analysis\n",
    "\"\"\"\n",
    "\n",
    "model_metrics = dict([])\n",
    "train_metric = np.zeros([nnodes, len(disorders)])\n",
    "test_metric = np.zeros(train_metric.shape)\n",
    "model_pval = np.zeros((len(disorders), ))\n",
    "\n",
    "for i in range(len(disorders)):\n",
    "    print(i)\n",
    "    m, _ = get_dominance_stats(receptor_data,\n",
    "                                     zscore(MIND_Dementia[:, i]))\n",
    "    model_metrics[disorders[i]] = m\n",
    "    # cross validate the model\n",
    "    train_metric[:, i], test_metric[:, i] = \\\n",
    "        cv_slr_distance_dependent(receptor_data, zscore(MIND_Dementia[:, i]),\n",
    "                                  coords, .75, metric='corr')\n",
    "    # get p-value of model\n",
    "    model_pval[i] = get_reg_r_pval(receptor_data,\n",
    "                                   zscore(MIND_Dementia[:, i]), \n",
    "                                   spins, nspins)\n",
    "\n",
    "model_pval = multipletests(model_pval, method='fdr_bh')[1]\n",
    "\n",
    "dominance = np.zeros((len(disorders), len(receptor_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6773ee44-df40-4b15-a2a8-a0a7dcc4f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "# FDR Correction\n",
    "model_pval_corrected = fdrcorrection(model_pval)[1]\n",
    "\n",
    "print(model_pval_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b9425-ceb3-49db-bc53-0d701eb86fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model_metrics)):\n",
    "    tmp = model_metrics[disorders[i]]\n",
    "    dominance[i, :] = tmp[\"total_dominance\"]\n",
    "np.save(path+'results/dominance_enigma.npy', dominance)\n",
    "np.save(path+'results/enigma_cv_train.npy', train_metric)\n",
    "\n",
    "plt.ion()\n",
    "plt.figure()\n",
    "plt.bar(np.arange(len(disorders)), np.sum(dominance, axis=1),\n",
    "        tick_label=disorders)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.tight_layout()\n",
    "plt.savefig(path+'figures/bar_dominance.eps')\n",
    "\n",
    "dominance[np.where(model_pval_corrected >= 0.05)[0], :] = 0\n",
    "plt.ion()\n",
    "plt.figure()\n",
    "sns.heatmap(dominance / np.sum(dominance, axis=1)[:, None],\n",
    "            xticklabels=receptor_names, yticklabels=disorders,\n",
    "            cmap=cmap_seq, linewidth=.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path+'figures/heatmap_dominance.eps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d93ab9e-87af-4c42-9477-b7ab6d3fe7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_pval)\n",
    "print(dominance)\n",
    "print(np.sum(dominance, axis=1))\n",
    "print(dominance / np.sum(dominance, axis=1)[:, None])\n",
    "PVALUE = model_pval\n",
    "ADJUSTR = np.sum(dominance, axis=1)\n",
    "PERCENT = 100*(dominance / np.sum(dominance, axis=1)[:, None])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
